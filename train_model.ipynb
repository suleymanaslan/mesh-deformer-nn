{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.utils import ico_sphere\n",
    "from pytorch3d.loss import chamfer_distance, mesh_edge_loss, mesh_laplacian_smoothing, mesh_normal_consistency\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import utils\n",
    "import batch_iterator\n",
    "import models\n",
    "import create_data\n",
    "\n",
    "training_timestamp = str(int(time.time()))\n",
    "model_dir = f'trained_models/model_{training_timestamp}/'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_log(text):\n",
    "    print(text)\n",
    "    print(text, file=open(f'{model_dir}/log.txt', 'a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pointcloud(pointcloud, title=\"\", from_mesh=False, points_to_sample=5000):\n",
    "    if from_mesh:\n",
    "        points = sample_points_from_meshes(pointcloud.to(device), points_to_sample)\n",
    "        x, y, z = points.clone().detach().cpu().squeeze().unbind(1)\n",
    "    else:\n",
    "        x, y, z = torch.from_numpy(pointcloud).unbind(1) \n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = Axes3D(fig)\n",
    "    ax.scatter3D(x, z, -y)\n",
    "    plt.axis('off')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(190, 30)\n",
    "    plt.savefig(f\"{model_dir}/{title}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_to_sample = 1000\n",
    "sphere_level = 3\n",
    "sphere_level_verts = {2: 162, 3: 642, 4: 2562}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'data/'\n",
    "if len(os.listdir(os.path.join(os.getcwd(), folder_path))) < 300:\n",
    "    create_data.create_data('meshes/', 50, points_to_sample, sphere_level)\n",
    "shutil.copy2('./train_model.ipynb', model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = utils.get_model_names(folder_path)\n",
    "training_x, training_y, test_x, test_y = utils.read_data(model_names, folder_path, points_to_sample, sphere_level_verts[sphere_level])\n",
    "batch_iter = batch_iterator.BatchIterator(training_x, training_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.PointNetCls(sphere_level_verts[sphere_level]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "train_epoch_step = int(round(batch_iter.size / batch_size))\n",
    "val_epoch_step = int(round(test_x.shape[0] / batch_size))\n",
    "display_steps = np.linspace(1, train_epoch_step, 10, endpoint=True).astype(np.uint32)\n",
    "train_losses = []\n",
    "train_epoch_losses = []\n",
    "val_losses = []\n",
    "lowest_val_loss = np.inf\n",
    "best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "src_mesh = ico_sphere(sphere_level, device)\n",
    "w_chamfer = 1.0 \n",
    "w_edge = 0.05\n",
    "w_normal = 0.0005\n",
    "w_laplacian = 0.005\n",
    "for epoch_i in range(1, epochs+1):\n",
    "    print_and_log(f\"{datetime.now()} Epoch:{epoch_i}, Training\")\n",
    "    model.train()\n",
    "    train_epoch_loss = 0.0\n",
    "    for step_i in range(1, train_epoch_step+1):\n",
    "        batch_x, batch_y = batch_iter.next_batch()\n",
    "        batch_x = torch.transpose(torch.from_numpy(batch_x), 1, 2).to(device)\n",
    "        batch_y = torch.from_numpy(batch_y).to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        pred_y, _, _ = model(batch_x)\n",
    "\n",
    "        all_loss = 0.0\n",
    "        for pointcloud, deform_verts in zip(batch_x, pred_y):\n",
    "            pred_mesh = src_mesh.offset_verts(deform_verts)\n",
    "            pred_pc = sample_points_from_meshes(pred_mesh, points_to_sample)\n",
    "            pred_pc = pred_pc - torch.mean(pred_pc, axis=1)[0]\n",
    "            pred_pc = pred_pc / torch.max(pred_pc, axis=1)[0]\n",
    "            loss_chamfer, _ = chamfer_distance(torch.transpose(pointcloud, 0, 1).unsqueeze(0), pred_pc)\n",
    "            loss_edge = mesh_edge_loss(pred_mesh)\n",
    "            loss_normal = mesh_normal_consistency(pred_mesh)\n",
    "            loss_laplacian = mesh_laplacian_smoothing(pred_mesh, method=\"uniform\")\n",
    "            cur_loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "            all_loss += cur_loss\n",
    "        all_loss /= batch_size\n",
    "\n",
    "        all_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(all_loss.item())\n",
    "        train_epoch_loss += all_loss.item()\n",
    "        \n",
    "        if step_i in display_steps:\n",
    "            print_and_log(f\"{datetime.now()} Epoch:{epoch_i}, Training Step:{step_i}/{train_epoch_step}, \"\n",
    "                          f\"Iter:{step_i*batch_size}/{train_epoch_step*batch_size}, Loss Chamfer:{loss_chamfer * w_chamfer:.4f}, \"\n",
    "                          f\"Loss Edge:{loss_edge * w_edge:.4f}, Loss Normal:{loss_normal * w_normal:.4f}, Loss Laplacian:{loss_laplacian * w_laplacian:.4f}\")\n",
    "    \n",
    "    train_epoch_loss /= train_epoch_step\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "    \n",
    "    print_and_log(f\"{datetime.now()} Epoch:{epoch_i}, Validation\")\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_step_i in range(val_epoch_step):\n",
    "            batch_x = test_x[val_step_i*batch_size:val_step_i*batch_size+batch_size]\n",
    "            batch_y = test_y[val_step_i*batch_size:val_step_i*batch_size+batch_size]\n",
    "            batch_x = torch.transpose(torch.from_numpy(batch_x), 1, 2).to(device)\n",
    "            batch_y = torch.from_numpy(batch_y).to(device)\n",
    "            \n",
    "            pred_y, _, _ = model(batch_x)\n",
    "\n",
    "            all_loss = 0.0\n",
    "            for pointcloud, deform_verts in zip(batch_x, pred_y):\n",
    "                pred_mesh = src_mesh.offset_verts(deform_verts)\n",
    "                pred_pc = sample_points_from_meshes(pred_mesh, points_to_sample)\n",
    "                pred_pc = pred_pc - torch.mean(pred_pc, axis=1)[0]\n",
    "                pred_pc = pred_pc / torch.max(pred_pc, axis=1)[0]\n",
    "                loss_chamfer, _ = chamfer_distance(torch.transpose(pointcloud, 0, 1).unsqueeze(0), pred_pc)\n",
    "                loss_edge = mesh_edge_loss(pred_mesh)\n",
    "                loss_normal = mesh_normal_consistency(pred_mesh)\n",
    "                loss_laplacian = mesh_laplacian_smoothing(pred_mesh, method=\"uniform\")\n",
    "                cur_loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
    "                all_loss += cur_loss\n",
    "            all_loss /= batch_size\n",
    "            \n",
    "            val_epoch_loss += all_loss.item()\n",
    "            \n",
    "    val_epoch_loss /= val_epoch_step\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    print_and_log(f\"{datetime.now()} Epoch:{epoch_i}, Validation Loss:{val_epoch_loss:.6f}\")\n",
    "    if val_epoch_loss <= lowest_val_loss:\n",
    "        lowest_val_loss = val_epoch_loss\n",
    "        print_and_log(f\"{datetime.now()} Epoch:{epoch_i}, Best Validation Loss Obtained - Saving Model\")\n",
    "        best_model = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model)\n",
    "torch.save(model.state_dict(), f\"{model_dir}/model_{lowest_val_loss:.4f}.pth\")\n",
    "np.save(f\"{model_dir}/train_losses.npy\" , np.array(train_losses))\n",
    "np.save(f\"{model_dir}/train_epoch_losses.npy\" , np.array(train_epoch_losses))\n",
    "np.save(f\"{model_dir}/val_losses.npy\" , np.array(val_losses))\n",
    "\n",
    "train_plot_steps = np.arange(len(train_losses))+1\n",
    "val_plot_steps = (np.arange(len(val_losses))+1)*train_epoch_step\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Losses\")\n",
    "plt.plot(train_plot_steps, train_losses, label='train_loss', linewidth=3)\n",
    "plt.plot(val_plot_steps, train_epoch_losses, label='train_epoch_loss', linewidth=3)\n",
    "plt.plot(val_plot_steps, val_losses, label='val_loss', linewidth=3)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"{model_dir}/loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample_ix = 40\n",
    "plot_pointcloud(training_x[plot_sample_ix], \"mesh\")\n",
    "\n",
    "pred_deform_verts, _, _ = model(torch.transpose(torch.from_numpy(training_x[plot_sample_ix]), 0, 1).to(device).unsqueeze(0))\n",
    "plot_pointcloud(ico_sphere(sphere_level).offset_verts(pred_deform_verts.detach().cpu().squeeze()), \"predicted deformation\", from_mesh=True, points_to_sample=points_to_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "pytorch3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
